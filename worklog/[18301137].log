18301137 王磊的工作完成情况以及计划：

2020.06.30 上午
    完成了配置python、pycharm、java以及spark环境的相关操作，并且对github的管理更加明确，建立了worklog目录并写明了目录说明，来告知成员们怎样更新自己的日志文件。
    由于一位成员的错误操作，导致之前添加的目录等文件在github和本地库中均被删除，我在网上查找了很多相关资料，明白了用什么语句来找到之前的版本并找回被删除的文件。
虽然看到文件被删除后很崩溃，但是当学会如何恢复被删除的文件后，也觉得这是一件塞翁失马，焉知非福的事情。
    因为之后项目中会用到spark和Flask，因此对这两种技术的原理与运用有了一些了解，为之后的项目开发做了一些铺垫。

2020.06.30 下午
    昨天下载了坚果VPN作为翻墙工具，但只能免费1天，而且之后每个月收费32元，因此询问了同学别的便宜的VPN软件。在www.maoni.com网站上花10块钱买了一个VPN，但是无奈
按照教程重复了许多遍，改变了很多设置，也询问了同学，这个软件还是无法应用，白白亏损了10元。所以暂时先使用坚果VPN翻墙，等到有空时再继续钻研www.maoni.com网站。
    另外，完成了spark相关的环境配置，在NOAA网站获取了北京1980/1/1到2020/6/27日的每日最高气温、最低气温、平均气温以及降雨量等数据，但是由于网站的问题，点击阳光
和水时，网站会出错，因此没有下载阳光、水的相关数据，尚不明确这是否会对之后的数据分析产生影响，若有影响，之后可考虑其他方法将所有数据下载完成。
    然后，在任务7安装依赖包时，安装Statsmodels、Pandas、Numpy时操作正常，但是当安装Matplotlib时显示无法找到对应版本，所以选择了更新pip到最新版本，然后再下载
Matplotlib则成功。通过这次的环境配置，我觉得环境配置也是工程中的一个难点，是十分令人头疼的。
    目前环境还差虚拟机和spark集群的配置，这两个配置将在今晚和明早尽快完成，计划明天完成spark数据清洗与ARIMA模型研究。

2020.07.01
    今天上午首先进行了虚拟机配置的尝试，下载完Vmware在安装时，发现硬盘空间不够，原因是C盘剩余空间大小不够。然后又仔细阅读了一遍文档，发现配置虚拟机主要是为了对
数据进行清洗，即挑选出我们需要的完整数据，因此这项工作不需要所有的组员都完成，只要有一个人完成了数据清洗，便可以将这个数据导出给其他组员，并且数据清洗还可以使用
Windows版本的，配置虚拟机的目的主要是对叫大批量的数据进行操作，但是我们决定先完成北京的数据，因此决定先不配置虚拟机以及spark集群，当后面进行大批量数据操作时再
进行配置。
    之后，我便一直在研究ARIMA模型，查找了很多博客和网站，看到了很多人对于ARIMA模型的理解，目前学到了一些关于该模型的知识，也尝试了对python代码的模仿与编写，但是
目前只是生成了北京气温数据的曲线图，后面的对数据的差分，求自相关函数、偏自相关函数等的代码还未成功实现，主要是因为之前接触的python很少，对python代码很不熟悉，因此
明天将对python进行相关学习。通过看博客，我现在知道了AR和MA模型的概念，也知道了预测数据的流程，但是某些具体细节还没有看懂。
    明日计划：继续研究ARIMA模型以及python语法，争取可以在明天完成一遍整个气温预测的流程，为之后大批量数据的预测做铺垫。

2020.07.02
    今天一天都在看CSDN上对ARIMA和ARMA模型的讲解与代码示范，与昨天相比，今天对ARIMA的了解更深入了，基本对AR、MA、ARMA、ARIMA模型都有了一定的认识，并知道了模型参数
中p、d、q的含义以及参数的计算方法。目前了解到的参数计算方法主要有三种：（i）ACF和PACF定阶：通过自相关函数和偏自相关函数，画出两个图像，然后人为分别读取出q和p的值，
但是这种方法不适合普遍情况，因为无法通过计算机自身来获取参数的值(ii)信息准则定阶：包括AIC、BIC、HQ准则等，这种方法的思路一般是遍历所有可能的p、q、d的取值，然后对
所有这些情况计算相应的值，选取值最小的一种参数组合作为模型的参数。此方法适合计算机执行，并且今天已经用代码测试了BIC准则，效果还不错。(iii)热力图定阶:此方法和(ii)
类似，只不过值的表达是应用的热力图的方式，使得结果更加直观，人们更容易读取出p、q的取值，但是对于计算机来说，这种方法是不太合适的。除此之外，还进行了平稳序列的检测，
以及通过差分法获取平稳序列、白噪声检测、对模型效果的分析等等，这些操作均通过代码进行了实现。
    到此为止，今天已经完成了昨日的计划，用代码完整的实现了对北京6月28日气温的预测，并对python代码以及语法有了更多地了解，基本可以看懂博客上关于模型的相关代码，但是
对某些python语句还是不理解，在之后还需要继续对python进行熟悉。目前对ARIMA模型的理解肯定还有不太好的地方，但暂时先放下对模型的研究，继续完成后面的工作，等之后项目进度
完成的较好时，再对ARIMA模型进行更深入的研究，争取将ARIMA模型研究透。
    明日计划：创建一个python处理类，写一个标准化的处理程序，对不同日期的数据进行预测，并对预测后的数据进行处理，生成标准化的JSON数据，若时间仍充裕，就了解一下数据
传输方面的知识，学会如何将JSON数据传输出去。
    
2020.07.03
    今天上午将昨天写的ARIMA模型的代码整合了一下，完整的写了一个ARIMA模型预测数据的代码，但在p、q参数的求解上还有一些不理解，查阅了很多资料，只是大概有了一个了解，
但是在具体的实现上，网络上也没有给出一个很好的例子，因此目前只是大概确定了一个p、q参数，先在这个参数的基础上完成后面的过程，最后有时间再返回来研究参数的优化。之后
根据写的ARIMA模型的代码，编写了一个python处理类，用于其他文件对ARIMA预测的调用，封装成了一个类和相应的函数，其他文件需要用模型预测时仅需要新建一个类并调用函数即可。
然后通过在网上查阅相关资料，完成了将处理后的数据转换为Json格式的数据，生成了标准化的Json数据格式，并也将这部分代码封装成了函数，便于其他文件的调用。然后，便开始了
对Flask的研究，用pip完成了Flask的安装配置，也成功通过几行代码完成了最简单的一个demo，通过http://192.168.10.7:5023/（ip+端口）网址进行了访问，是一个空白的网页。
目前，正在研究Flask的路由配置，还没有开始写这一部分的代码。
    我会在一会将今天所写的python文件上传到我的分支——wl分支。
    明日计划：完成Flask的路由配置及相关代码的编写，然后对socket数据传输进行研究，有时间的话在看看微服务架构设计的相关知识。
    
2020.07.04
    今天，首先查找了关于Flask的资料，了解了Flask的作用，然后对Flask的路由配置进行了研究，明白了通过@app.route("/")语句来控住路由，当在URL中输入这个路由时，便会调用
这个路由下编写的函数。另外也查看了动态URL的相关资料，实现了一个简单的Demo，是用@app.route('/user/<username>')语句完成的，思想就是在URL中随机输入一个username，这个
username便相当于一个参数传给服务器，然后在页面中将参数显示出来。
    然后，为了完成Json数据传输便开始学习了socket的相关知识，在网上查阅了资料，对socket的思想和实现有了一些认识，便开始了数据传输代码的编写，目前已将代码完成并上传到
了wl分支，但是还没有对这个文件进行测试，尚不清楚时候能正确的将数据传输出去。之后，看了一些微服务架构设计的知识，但是还没有理解其内容，也不清楚如何用Java调用python的
接口，明天首先将这些工作完成，然后开始与负责前端的同学进行交接，尽量能够将前后端实现简单的连接。
    今天写的代码已经上传到了wl分支。

2020.07.05
    今天的进度相比于前几天可以说是最慢的一天了，也是最烦躁的一天。。。
    上午，我查找了关于用Flask建立微服务的相关资料，看到了很多解释，也看到了其他人写的代码示例，但始终还是不太理解这个微服务怎么用的。在这个地方卡主之后，便开始继续
往下看任务，接下来就是和Java语言相关的内容，因为前段有专门的同学来负责，所以就开始了与负责前端的同学的讨论，讨论了一番，还是对整个网络连接有不清楚的地方，不了解到底
是怎样的一个过程。
    下午，继续上午的工作，查找如何将python与java实现接口对接，即如何将用flask写的程序与用java写的前端程序构成网络连接，经过一番查找，了解到flask可以创建一个网站，
类似于http：//127.0.0.1:9000/这种格式，而前端正是用Websocket与这个类似网站的URL进行连接，到这里，我们才对整个任务流程有了一些理解，也大概明白了python程序是如何与
java程序对接的。但是由于时间有限，目前还没能达到两部分的连接，争取在明天搞定这部分的内容。另外，有组员提到如何预测所有日期的气温，要是预测所有日期气温的话，也需要
每个日期的数据，所以之前获取的北京每年6.28的气温数据就不够用了，然后便研究如何将全部日期的数据提取出来，经过询问其他组的同学后，得知只需把数据清洗中的query部分代码
删除即可。然后再用其他日期的数据来训练模型时，发现之前写的python处理类出现了error，错误是SVD不收敛，经过查询，发现是p、q参数设置不合理，知道这个之后我便很烦躁，这
就意味着我们之前写的模型有错误，便开始对身边其他同学的询问，问了很多同学后，得知他们也遇到了这种问题，并且有不少小组已经抛弃了ARIMA模型，改用其他的模型。在经过小组
内部的讨论之后，我们也决定更换模型，改用auto_arima模型，目前正在对这个模型进行研究，写了一些代码，但还没完全成功，争取在明天完成模型的改变。
    明日任务：完成模型的改进，争取与前端同学建立连接。

2020.07.06
    今天也是极其崩溃的一天，截止到下午五点，也就是刚刚，才终于将python处理类中的ARIMA模型成功改成了auto_arima模型，虽然改动的代码比较少，但对于我来说这确实是一个飞跃
从昨天晚上11点开始改，到凌晨两点都没能改对，今天下午两点，问了问其他组的同学是怎样改的，结果在我这里也不能实现，然后自己又尝试了再尝试，终于将模型改进成功，不仅可以较
好地预测出气温数据，还可以与之后的数据处理的格式统一，其实卡住的地方就是数据格式不统一的问题，不过幸好，他终于能够成功运行了。
    我也知道我们组的进度比较慢，所以今天上午也是一直在听其他组和老师们的讲解，有的组已经基本将任务完成，这时我感到了很大的压力，因此较难的Websocket问题还没能攻破，这
也是我今天晚上将要研究的问题，抓紧实现与前端同学的连接，如果晚上有进展，今晚会继续更新log。

    模型更改以及通过参数确定预测日期的代码已上传到wl分支
    
    在flask里添加了预测生成一周连续七天的函数，然后将这七天的气温数据传给前端。由于每次跑模型都需要几秒时间，因此会对用户造成很差的体验，所以暂时决定将几个城市的所有数据
提前预测出来，之后直接调用即可。

2020.07.07
    今天上午，和组员一起商量要怎样处理老师给的大量问题，因为数据下载下来后，每年每个地方的数据都是分开的，而且只有打开csv文件后才能直到文件对应的是哪个城市的数据，因此
讨论后决定，不再使用老师给的那100多G数据，而是自己去NOAA官网上下载几个城市的历史数据，然后分别对每个城市每天的气温数据做预测，将结果记录到csv文件中，这样前端调用的时候
便不再需要等待跑模型的时间了，可以增强用户的体验感。
    然后，还是继续了昨天的工作，看了一些Websocket的连接方式，但是仍然没有看的很懂，由于在这个地方已经消耗了大量时间，所以决定不再研究websocket，转为用socket连接，传输
预测的气温数据，经过测试与改进，目前已经可以达成java与python的连接，数据也可以传输，但是还没能完成传输七天的气温数据，今天晚上将会继续写这一功能的代码，争取今晚将网络
连接的传输数据功能实现。
    今天的代码已上传到wl分支。
来自凌晨更新：
    经过一晚上的研究，终于能够实现了java和python的网络连接，现在java可以给python传month和day两个参数，然后python把以后七天每天气温的最大最小值用json数据格式传给java，
并且我已把java那边的数据已经都转换成double格式，所以前端直接调用这些数据生成图像即可，卡了将近3天的网络连接传输数据终于完成了！！！！！！
    因为我们的目标是前端显示几个城市的气温预测，所以目前的网络连接传递的参数还少了一个城市的参数city，这个参数我会在明天加到java和python的函数中。另外，明天也会和前端的
同学完成合并，使我写的java代码可以加到前端上并正常运行。然后，就可以给负责前端的同学分担一些任务，首先配置SpringMVC，然后完成角色管理等方面的代码。
    今晚的代码已上传到wl分支。

2020.07.08
    今天上午，按照计划进行，已经完成了网络的city参数传输，可以按照city参数获取不同城市的数据，将连续七天的气温数据传输给java，今天上午在数据类型转换上耗时较多，但最终也
成功将数据转换为了摄氏度数据，格式也与前端同学达成了一致。另外，今天上午我和组员一直在会议中讨论，知道了目前所有人的大概进度与任务计划，总体来看，python端的代码只剩下在
flask中加入socket传输，这个任务我会在下午花一些时间来完成，然后就是前端的数据预测曲线与一些角色、部门、全向等管理功能，项目进度在计划之中，之前最难的几天也终于熬过去了，
看到了胜利的曙光。下午我还会帮助前端的同学看一些角色管理方面的代码，写一写静态html页面。
    新的网络传输代码已上传到wl分支。
    下午前端的同学在调用我写的socket传输的代码时，选择某些日期时返回的数据会有差错，然后我便对程序进行了debug,一步步的把程序最终改完整，目前所有城市和日期的数据返回结果
均已正常，已交付给前端同学正常使用，更改之后的网络传输的java和python代码已上传到wl分支。之后便开始研究角色管理、部门管理等相关代码的实现，在github下载了一些类似功能的项目
想从别人的代码中学习如何写角色管理功能，但是我的电脑上还没有配置springMVC以及java Maven项目等的环境，目前尝试了很多的配置方案，都没有能够成功，一会再找找其他解决方案尝试
一下。
    明日计划：完成springmvc等环境的配置，写出了一个角色管理功能的代码，并尽量与前段完成对接。然后再更改下socket传输的代码，使得可以互相传输的数据覆盖更多的城市。

2020.07.09
    凌晨，SpringMVC已基本配置完，但目前的测试项目还没能成功运行，应该是代码写的不正确，明天起床继续将测试项目完成。
    今天上午成功将springmvc环境配置成功，并且向前端同学要了项目代码，已经成功将项目运行，然后看了前端同学写的代码，大概有了一个了解。目前正在研究角色管理功能，在github上
下载了一些别人写过的相关的代码，但是内容都比较多，而且用到了很多框架，需要配很多环境，但在redis和mysql等环境配置好后，他们的项目还是不能在我的电脑上运行，所以决定不再从
大型项目上学习如何实现角色管理功能，而是从百度进行搜索，一步一步的学习。下午继续学习数据库以及角色管理功能的实现，争取今天能够将项目连接好数据库并完成角色管理功能。
    今天下午和晚上看了很多关于角色管理的东西，发现需要配置一些文件，所以先下载了mysql数据库、redis、mybatis以及Navicat 15 for mysql数据库的可视化软件。下载完环境后，便
在百度上找了很多关于角色管理的教程，按照几个教程一步步的进行了，目前java、js、xml、html等文件已经全部写到了测试项目中，也下载了相关的jar包导入到了项目中，目前项目可以运行
，但是无法实现登录功能，初步查看应该是数据库文件的配置问题，使得项目无法连接到本地的数据库，在网络上查了一些资料，但还是没能成功，一会将继续研究这个bug。
    用户管理的测试项目将上传到wl分支。
    明日计划：完成用户管理的功能，然后再在此基础上研究如何实现部门、角色、权限管理。由于明天晚上有2020级大创答辩，而我们小组有包括我在内的4个人参加了2020年大创，所以明天
白天进度可能会比较慢，但是我们的项目还有一些功能为完成，目前只剩下了三天的时间，所以我们明天需要加班，争取完成更多任务。

2020.07.10
    今天上午，由于要完成大创的ppt，所以进度有些慢。因为目前宋廷泽和杨翔越已经将全国28个省份和自治区的气象预测数据整理完毕，所以我今天上午把这些新的预测数据加到了python和
java的文件中，通过调试和测试，目前代码已经可以正常运行，已交付给前端同学，由吴介豪将这些代码添加到前端，所以今天预计地图上的绝大部分地方都可以点击并显示出预测数据。
    今天下午，由于组内三个同学要准备晚上的大创答辩，所以他们的进度应该会比较慢。我计划今天下午继续研究用户管理功能，解决之前连不上数据库的bug，争取完成用户管理功能。
    今天下午，再次研究了关于数据库连接不上的问题，然而查了很久的资料，尝试了很多的办法，还是不能连接成功，也很崩溃。于是，打算不继续在这个项目上做研究，开始进行了其他的搜索
发现有一个maven项目也能够支持实现用户角色权限管理，所以按照这个教程进行了一遍尝试，然而就在数据库、配置文件、java文件、js等文件都配置好后，万事俱备，只欠东风，就在电机运行时
，eclipse报错了，原因是maven的plugin包找不到，但是我的项目里明明有这个包，于是又开始了查资料，改环境，调bug的不断尝试，遗憾的是，到目前为止，还是不能够运行maven项目，由于我的
eclipse环境配置问题，导致今天一天的进展很少，而现在也只剩写了两天去完成项目，能不能完成还是个未知数，明天起床再加加班，争取能有一些突破吧。

2020.07.11
    就在打算睡觉之前，又想再看几个解决方案，结果有了重大进展，在maven install项目上，突然多了几行正确信息，然后便有了一些希望，便又有了动力继续往下看，于是又开始查找新的error，
好像是从坑里爬出来是的，后来便一路顺风顺水，成功将maven项目build成功。当看到屏幕上BUILD SUCCESS时，心里也十分激动。于是不经意间又开始了测试昨天的用户管理测试项目，发现报错与
之前也不一样了，我也开始查资料，发现是数据库中没有对应的列，然后经过一番查找，发现是xml配置中的sql语句，与数据库中的列名不匹配，在更改数据库的列名后，发现项目可以成功的运行了！
今晚就到这里了，明天起来继续干，已将用户管理这部分的测试代码传到wl分支。
    今天，又研究了昨天的一个maven项目，当时经过无数次的查资料和尝试，还是不能将项目成功运行。目前是maven项目可以build成功，但是在浏览器输入网址后，一直都是404。无奈之下只能选
择了放弃。现在只有用户管理的功能已经实现，而角色管理、部门管理、权限管理等都没能实现，现在看来这些任务可能完不成了，所以尽量把现在做的再优化优化，用户管理的项目已经交给吴介豪
同学，由他将用户管理和气温预测的页面整合在一起。用户管理功能现在也实现了增删改查功能。晚上继续研究一下部门管理的内容，争取能够再有一些进展。若还是进展不大，则只好选择放弃那部分
准备最终的项目文档和答辩PPT。
    今天晚上，仔细研究了用户管理的代码，发现数据库中的几项可以更改为部门和角色，这样就可以简便的实现部门管理和角色管理的功能，于是，便将前端html文件和xml配置文件，以及java等文件
中的相关内容改变为了部门和角色，系统运行时，可以更改用户信息，包括用户名、密码、部门、角色等，也可以在系统中显示上一次修改的具体时间，这样便简单的达到了用户管理，部门管理，角色管理
的功能，但是目前还未能完成权限管理的功能，就是每个用户的权限基本是一样的，都可以增删改查，但由于时间问题，我们已不打算完成权限管理的内容，明天开始准备项目的文档和ppt。
    部门管理和角色管理内容的代码已上传到wl分支，也已交付给吴介豪同学，由他做最后的整合。

18301137 王磊的工作完成情况以及计划：

2020.06.30 上午
    完成了配置python、pycharm、java以及spark环境的相关操作，并且对github的管理更加明确，建立了worklog目录并写明了目录说明，来告知成员们怎样更新自己的日志文件。
    由于一位成员的错误操作，导致之前添加的目录等文件在github和本地库中均被删除，我在网上查找了很多相关资料，明白了用什么语句来找到之前的版本并找回被删除的文件。
虽然看到文件被删除后很崩溃，但是当学会如何恢复被删除的文件后，也觉得这是一件塞翁失马，焉知非福的事情。
    因为之后项目中会用到spark和Flask，因此对这两种技术的原理与运用有了一些了解，为之后的项目开发做了一些铺垫。

2020.06.30 下午
    昨天下载了坚果VPN作为翻墙工具，但只能免费1天，而且之后每个月收费32元，因此询问了同学别的便宜的VPN软件。在www.maoni.com网站上花10块钱买了一个VPN，但是无奈
按照教程重复了许多遍，改变了很多设置，也询问了同学，这个软件还是无法应用，白白亏损了10元。所以暂时先使用坚果VPN翻墙，等到有空时再继续钻研www.maoni.com网站。
    另外，完成了spark相关的环境配置，在NOAA网站获取了北京1980/1/1到2020/6/27日的每日最高气温、最低气温、平均气温以及降雨量等数据，但是由于网站的问题，点击阳光
和水时，网站会出错，因此没有下载阳光、水的相关数据，尚不明确这是否会对之后的数据分析产生影响，若有影响，之后可考虑其他方法将所有数据下载完成。
    然后，在任务7安装依赖包时，安装Statsmodels、Pandas、Numpy时操作正常，但是当安装Matplotlib时显示无法找到对应版本，所以选择了更新pip到最新版本，然后再下载
Matplotlib则成功。通过这次的环境配置，我觉得环境配置也是工程中的一个难点，是十分令人头疼的。
    目前环境还差虚拟机和spark集群的配置，这两个配置将在今晚和明早尽快完成，计划明天完成spark数据清洗与ARIMA模型研究。

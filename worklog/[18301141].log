18301141 杨翔越

2020/6/30 上午：
学习了github的使用，完成了项目文档里的任务1-5，主要进行了python环境变量的配置，编译器的下载，这些进行的还算顺利
但在进行任务5的时候遇到了一些困难，首先之前用的解压缩软件8-zip无法解压，换用了新的解压软件bandzip解决此问题
然后由于handoop需要下载windows下可以运行的bin文件，在这里依然遇到了一些问题，最后仍然有一些warning，但是昨天另一位同学出现同样的问题后老师说可以暂时不考虑这些warning


2020/6/30下午：
今天下午的进度很慢，主要是因为pip install一直有问题，第一次运行，提示我的pip不是最新版本，我根据提示进行了pip的更新升级
升级成功后再次进行pip install的时候还是进行了报错，而且好像每次错误出错的位置还不太一样，有是有已经进行了部分下载结果还是报错，下载的时间也很长，导致了下午的进度很慢
然后小组成员成功翻墙下载到了北京1980/1/1到现在的天气数据
希望今天可以解决pip install的问题


2020/7/1 整天：
上午通过挂vpn的方式成功解决了昨天pip install的问题，按照文档里的任务列表，进行虚拟机的安装配置工作，由于下载网站全英文且由于我自己没有仔细看，导致第一次下载了错误的文件，
从而导致了虚拟机的前几次安装尝试不成功，经过重新下载，上午结束时成功安装虚拟机

下午进行虚拟机网络配置，由于下载版本与文档里的版本不一致，前几次尝试都没有成功，然后通过网上自己找教程和同学指导，成功对虚拟机的网络进行配置
配置完成后，由于我对python没有任何基础，所以接下来的时间一直在学习python的编程基础，包括代码格式以及语法等，现在已经对python的使用有了一定的了解


2020/7/2 整天：
上午按照文档里的步骤，尝试对虚拟机安装Hadoop和spark集群，但是由于错误操作导致虚拟机系统奔溃，不得不重新安装虚拟机系统
重新安装系统过后，通过查阅资料，发现之前对虚拟机作用的理解有误，Hadoop是基于分布式的集群，需要三个虚拟机节点来完成工作，所以把现有的虚拟机作为主节点，再装了另外两个虚拟机作为从节点

下午由于对linux的操作还不是很熟悉，所以现在windows下尝试进行小规模数据的清洗，已经成功运行
运行成功后对ARIMA模型进行了学习，目前还没有实现
18301137 王磊的工作完成情况以及计划：

2020.06.30 上午
    完成了配置python、pycharm、java以及spark环境的相关操作，并且对github的管理更加明确，建立了worklog目录并写明了目录说明，来告知成员们怎样更新自己的日志文件。
    由于一位成员的错误操作，导致之前添加的目录等文件在github和本地库中均被删除，我在网上查找了很多相关资料，明白了用什么语句来找到之前的版本并找回被删除的文件。
虽然看到文件被删除后很崩溃，但是当学会如何恢复被删除的文件后，也觉得这是一件塞翁失马，焉知非福的事情。
    因为之后项目中会用到spark和Flask，因此对这两种技术的原理与运用有了一些了解，为之后的项目开发做了一些铺垫。

2020.06.30 下午
    昨天下载了坚果VPN作为翻墙工具，但只能免费1天，而且之后每个月收费32元，因此询问了同学别的便宜的VPN软件。在www.maoni.com网站上花10块钱买了一个VPN，但是无奈
按照教程重复了许多遍，改变了很多设置，也询问了同学，这个软件还是无法应用，白白亏损了10元。所以暂时先使用坚果VPN翻墙，等到有空时再继续钻研www.maoni.com网站。
    另外，完成了spark相关的环境配置，在NOAA网站获取了北京1980/1/1到2020/6/27日的每日最高气温、最低气温、平均气温以及降雨量等数据，但是由于网站的问题，点击阳光
和水时，网站会出错，因此没有下载阳光、水的相关数据，尚不明确这是否会对之后的数据分析产生影响，若有影响，之后可考虑其他方法将所有数据下载完成。
    然后，在任务7安装依赖包时，安装Statsmodels、Pandas、Numpy时操作正常，但是当安装Matplotlib时显示无法找到对应版本，所以选择了更新pip到最新版本，然后再下载
Matplotlib则成功。通过这次的环境配置，我觉得环境配置也是工程中的一个难点，是十分令人头疼的。
    目前环境还差虚拟机和spark集群的配置，这两个配置将在今晚和明早尽快完成，计划明天完成spark数据清洗与ARIMA模型研究。

2020.07.01
    今天上午首先进行了虚拟机配置的尝试，下载完Vmware在安装时，发现硬盘空间不够，原因是C盘剩余空间大小不够。然后又仔细阅读了一遍文档，发现配置虚拟机主要是为了对
数据进行清洗，即挑选出我们需要的完整数据，因此这项工作不需要所有的组员都完成，只要有一个人完成了数据清洗，便可以将这个数据导出给其他组员，并且数据清洗还可以使用
Windows版本的，配置虚拟机的目的主要是对叫大批量的数据进行操作，但是我们决定先完成北京的数据，因此决定先不配置虚拟机以及spark集群，当后面进行大批量数据操作时再
进行配置。
    之后，我便一直在研究ARIMA模型，查找了很多博客和网站，看到了很多人对于ARIMA模型的理解，目前学到了一些关于该模型的知识，也尝试了对python代码的模仿与编写，但是
目前只是生成了北京气温数据的曲线图，后面的对数据的差分，求自相关函数、偏自相关函数等的代码还未成功实现，主要是因为之前接触的python很少，对python代码很不熟悉，因此
明天将对python进行相关学习。通过看博客，我现在知道了AR和MA模型的概念，也知道了预测数据的流程，但是某些具体细节还没有看懂。
    明日计划：继续研究ARIMA模型以及python语法，争取可以在明天完成一遍整个气温预测的流程，为之后大批量数据的预测做铺垫。

2020.07.02
    今天一天都在看CSDN上对ARIMA和ARMA模型的讲解与代码示范，与昨天相比，今天对ARIMA的了解更深入了，基本对AR、MA、ARMA、ARIMA模型都有了一定的认识，并知道了模型参数
中p、d、q的含义以及参数的计算方法。目前了解到的参数计算方法主要有三种：（i）ACF和PACF定阶：通过自相关函数和偏自相关函数，画出两个图像，然后人为分别读取出q和p的值，
但是这种方法不适合普遍情况，因为无法通过计算机自身来获取参数的值(ii)信息准则定阶：包括AIC、BIC、HQ准则等，这种方法的思路一般是遍历所有可能的p、q、d的取值，然后对
所有这些情况计算相应的值，选取值最小的一种参数组合作为模型的参数。此方法适合计算机执行，并且今天已经用代码测试了BIC准则，效果还不错。(iii)热力图定阶:此方法和(ii)
类似，只不过值的表达是应用的热力图的方式，使得结果更加直观，人们更容易读取出p、q的取值，但是对于计算机来说，这种方法是不太合适的。除此之外，还进行了平稳序列的检测，
以及通过差分法获取平稳序列、白噪声检测、对模型效果的分析等等，这些操作均通过代码进行了实现。
    到此为止，今天已经完成了昨日的计划，用代码完整的实现了对北京6月28日气温的预测，并对python代码以及语法有了更多地了解，基本可以看懂博客上关于模型的相关代码，但是
对某些python语句还是不理解，在之后还需要继续对python进行熟悉。目前对ARIMA模型的理解肯定还有不太好的地方，但暂时先放下对模型的研究，继续完成后面的工作，等之后项目进度
完成的较好时，再对ARIMA模型进行更深入的研究，争取将ARIMA模型研究透。
    明日计划：创建一个python处理类，写一个标准化的处理程序，对不同日期的数据进行预测，并对预测后的数据进行处理，生成标准化的JSON数据，若时间仍充裕，就了解一下数据
传输方面的知识，学会如何将JSON数据传输出去。
    
2020.07.03
    今天上午将昨天写的ARIMA模型的代码整合了一下，完整的写了一个ARIMA模型预测数据的代码，但在p、q参数的求解上还有一些不理解，查阅了很多资料，只是大概有了一个了解，
但是在具体的实现上，网络上也没有给出一个很好的例子，因此目前只是大概确定了一个p、q参数，先在这个参数的基础上完成后面的过程，最后有时间再返回来研究参数的优化。之后
根据写的ARIMA模型的代码，编写了一个python处理类，用于其他文件对ARIMA预测的调用，封装成了一个类和相应的函数，其他文件需要用模型预测时仅需要新建一个类并调用函数即可。
然后通过在网上查阅相关资料，完成了将处理后的数据转换为Json格式的数据，生成了标准化的Json数据格式，并也将这部分代码封装成了函数，便于其他文件的调用。然后，便开始了
对Flask的研究，用pip完成了Flask的安装配置，也成功通过几行代码完成了最简单的一个demo，通过http://192.168.10.7:5023/（ip+端口）网址进行了访问，是一个空白的网页。
目前，正在研究Flask的路由配置，还没有开始写这一部分的代码。
    我会在一会将今天所写的python文件上传到我的分支——wl分支。
    明日计划：完成Flask的路由配置及相关代码的编写，然后对socket数据传输进行研究，有时间的话在看看微服务架构设计的相关知识。
